{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook setup\n",
    "# ============================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Control figure size\n",
    "interactive_figures = False\n",
    "if interactive_figures:\n",
    "    %matplotlib widget\n",
    "    figsize=(9, 3)\n",
    "else:\n",
    "    figsize=(14, 4)\n",
    "\n",
    "from util import util\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Load data\n",
    "data_folder = os.path.join('..', 'data')\n",
    "data = util.load_communities_data(data_folder)\n",
    "\n",
    "# Standardize and separate train and test data\n",
    "attributes, target = data.columns[3:-1], data.columns[-1]\n",
    "nf = [a for a in attributes if a != 'race'] + [target]\n",
    "\n",
    "tr_frac = 0.8 # 80% data for training\n",
    "tr_sep = int(len(data) * tr_frac)\n",
    "tmp = data.iloc[:tr_sep]\n",
    "\n",
    "sdata = data.copy()\n",
    "sdata[nf] = (sdata[nf] - tmp[nf].mean()) / (tmp[nf].std())\n",
    "\n",
    "sdata[attributes] = sdata[attributes].astype(np.float32)\n",
    "sdata[target] = sdata[target].astype(np.float32)\n",
    "\n",
    "tr = sdata.iloc[:tr_sep]\n",
    "ts = sdata.iloc[tr_sep:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained ML via Lagrangians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fairness as a Constraint\n",
    "\n",
    "**Let's recap our goals:**\n",
    "\n",
    "We want to train an accurate regressor ($L = \\operatorname{MSE}$):\n",
    "\n",
    "$$\n",
    "\\operatorname{argmin}_{\\theta} \\mathbb{E}\\left[ L(\\hat{y}, f(\\hat{x}, \\theta)) \\right]\n",
    "$$\n",
    "\n",
    "We want to measure fairness via the DIDI:\n",
    "\n",
    "$$\n",
    "\\operatorname{DIDI}(y) = \\sum_{j \\in J_p} \\sum_{v \\in D_{j}} \\left|\\frac{1}{m} \\sum_{i=1}^m y_i - \\frac{1}{|I_{j,v}|} \\sum_{i \\in I_{j,v}} y_{i}\\right|\n",
    "$$\n",
    "\n",
    "...And we want the DIDI to be low, e.g.:\n",
    "\n",
    "$$\n",
    "\\operatorname{DIDI}(y) \\leq \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fairness as a Constraint\n",
    "\n",
    "**We can use this information to re-state the training problem**\n",
    "\n",
    "$$\n",
    "\\operatorname{argmin}_{\\theta} \\left\\{ \\mathbb{E}\\left[ L(\\hat{y}, f(\\hat{x}, \\theta)) \\right] \\mid \\operatorname{DIDI}(f(\\hat{x}, \\theta)) \\leq \\varepsilon \\right\\}\n",
    "$$\n",
    "\n",
    "* Training is now a _constrained optimization_ problem\n",
    "* We require the DIDI _for ML output_ to be within acceptable levels\n",
    "\n",
    "After training, the constraint will be _distilled_ in the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are requiring constraint satisfaction _on the training set_**\n",
    "\n",
    "...Meaning that we'll have _no satisfaction guarantee on unseen examples_\n",
    "\n",
    "* This is suboptimal, but doing better is very difficult\n",
    "* ...Since our constraint is defined (conceptually) _on the whole distribution_\n",
    "\n",
    "We'll trust the model to generalize well enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=big>How can we account for the constraint at training time?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>There's more then one method: we'll see the the most famous one in ML</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constrained Machine Learning\n",
    "\n",
    "**Let's consider ML problem with _constrained output_**\n",
    "\n",
    "In particular, let's focus on problems in the form:\n",
    "$$\n",
    "\\text{argmin}_{\\theta} \\left\\{ L(y) \\mid g(y) \\leq 0 \\right\\} \\quad\\text{ with: } y = f(\\hat{x}, \\theta)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $L$ is the loss (the notation omits ground truth label for sake of simplicity)\n",
    "* $\\hat{x}$ is the training input\n",
    "* $y$ is the ML model output, i.e. $f(x, \\theta)$\n",
    "* $\\theta$ is the parameter vector (we assume a parameterized model)\n",
    "* $g$ is a constraint function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constrained Machine Learning\n",
    "\n",
    "**Example 1: logical _rules_**\n",
    "\n",
    "E.g. hiearchies in multi-class classification (\"A dog is also an animal\"):\n",
    "$$\n",
    "y_{i,dog} \\leq y_{i,animal}\n",
    "$$\n",
    "* This constraint is defined over _individual examples_\n",
    "\n",
    "**Example 2: _shape_ constraints**\n",
    "\n",
    "E.g. input $x_j$ cannot cause the output to decrease (monotonicity)\n",
    "$$\n",
    "y_{i} \\leq y_{k} \\quad \\forall i, k : x_{i,j} \\leq x_{k,j} \\wedge x_{i,h} = x_{k,h} \\forall h \\neq j\n",
    "$$\n",
    "* This is a _relational constraint_, i.e. defined over multiple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Methods for Constrained ML\n",
    "\n",
    "**One way to deal with this problem is to rely on a _Lagrangian Relaxation_**\n",
    "\n",
    "Main idea: we _turn the constraints into penalty terms_:\n",
    "\n",
    "* From the original constrained problem:\n",
    "\n",
    "$$\n",
    "\\text{argmin}_{\\theta} \\left\\{ L(y) \\mid g(y) \\leq 0 \\right\\} \\quad\\text{ with: } y = f(\\hat{x}, \\theta)\n",
    "$$\n",
    "\n",
    "* We obtain the following _unconstrained_ problem:\n",
    "\n",
    "$$\n",
    "\\text{argmin}_{\\theta} L(y) + \\lambda^T \\max(0, g(y)) \\quad\\text{ with: } y = f(\\hat{x}, \\theta)\n",
    "$$\n",
    "\n",
    "* The new loss function is known as a _Lagrangian_\n",
    "* $\\max(0, g(y))$ is sometimes known as _penalizer_ (or Lagrangian term)\n",
    "* ...And the $\\lambda$ is a vector of _multipliers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Methods for Constrained ML\n",
    "\n",
    "**Let's consider again the modified problem:**\n",
    "\n",
    "$$\n",
    "\\text{argmin}_{\\theta} L(y) + \\lambda^T \\max(0, g(y)) \\quad\\text{ with: } y = f(\\hat{x}, \\omega)\n",
    "$$\n",
    "\n",
    "* When the constraint is _satisfied_ ($g(y) \\leq 0$), the penalizer is 0\n",
    "* When the constraint is _violated_ ($g(y) \\leq 0$), the penalizer is > 0\n",
    "* Hence, in the _feasible area_, we still have the _original loss_\n",
    "* ...In the _infeasible area_, we incur a penalty that can be controlled using $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore:**\n",
    "\n",
    "* Assuming that $L(y)$ stays finite, if we choose $\\lambda$ large enough\n",
    "* ...We can guarantee that a feasible solution is found\n",
    "\n",
    "This is the basis of the classical [penalty method](https://en.wikipedia.org/wiki/Penalty_method#:~:text=Penalty%20methods%20are%20a%20certain,of%20the%20original%20constrained%20problem.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Methods for Constrained ML\n",
    "\n",
    "**Some comments**\n",
    "\n",
    "Lagrangian approches are [a classic in numeric optimization](https://web.stanford.edu/~boyd/cvxbook/)\n",
    "\n",
    "* But their use in ML is much more recent\n",
    "* One of the first instances is in [the Semantic Based Regularization (SBR) paper](https://www.sciencedirect.com/science/article/pii/S0004370215001344)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraints can depend on the _sample input_\n",
    "\n",
    "* In the fairness case it does not make sense, but there are other examples\n",
    "* E.g. different physical laws depending on object type\n",
    "* They still count as out constraint, since the input is a-priori known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraint satisfaction can be _framed in probabilistic terms_\n",
    "\n",
    "* This is one of the key ideas in most neuro-symbolic approaches\n",
    "* The SBR paper is a good reference; also check [Neural Markov Logic Networks](https://proceedings.mlr.press/v161/marra21a.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Methods for Constrained ML\n",
    "\n",
    "**Other comments:**\n",
    "\n",
    "For some _specific cases_, the $\\max(\\cdot)$ operator is not necessary\n",
    "\n",
    "* The Lagrangian term is instead just $\\lambda^T g(y)$\n",
    "* This is mostly the case when duality holds\n",
    "* ...BUt we will not focus on this topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Equality constraints_ (i.e. $g(y) = 0)$ can be modeled using two inequalities\n",
    "\n",
    "* The two resulting penalizers can be simplified as $\\lambda^T |g(y)|$\n",
    "* Using a quadratic term, i.e. $g(y)^2$ is also possible\n",
    "* The latter approach is common in augmented Lagrangian methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Methods for Constrained ML\n",
    "\n",
    "**Yet more comments:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feasibility guarantees have _some caveats_:\n",
    "\n",
    "* In particular they assume that a feasible solution exists\n",
    "* ...And that the problem is _solved to optimality_\n",
    "* ...Which we will not do! So, _some violation is possible_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware of differentiability!\n",
    "\n",
    "* The approach we discuss _does not_ require it\n",
    "* ...But _our implementation will_, since we'll be using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A Practical Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Back to Our Fairness Constraint\n",
    "\n",
    "**Ideally, we wish to train an ML model by solving**\n",
    "\n",
    "$$\n",
    "\\operatorname{argmin}_{\\theta} \\left\\{ \\mathbb{E}\\left[ L(\\hat{y}, f(\\hat{x}, \\theta)) \\right] \\mid \\operatorname{DIDI}(f(\\hat{x}, \\theta)) \\leq \\varepsilon \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we obtain _a Lagrangian term for our constraint_:\n",
    "\n",
    "$$\n",
    "\\lambda \\max\\left(0, \\operatorname{DIDI}(f(\\hat{x}, \\theta)) - \\varepsilon \\right)\n",
    "$$\n",
    "\n",
    "* We just have one constraint, so $\\lambda$ is a scalar\n",
    "* The threshold (i.e. $\\varepsilon$) has been incorporated in the term\n",
    "* The DIDI formula is differentiable, so we can use a NN for $f$\n",
    "* ...Otherwise, we would have needed to use a differentiable approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Back to Our Fairness Constraint\n",
    "\n",
    "**With the Lagrangian term, we can modify the loss function:**\n",
    "\n",
    "$$\n",
    "\\operatorname{argmin}_{\\theta} \\mathbb{E}\\left[ L(\\hat{y}, f(\\hat{x}, \\theta)) +\\lambda \\max\\left(0, \\operatorname{DIDI}(f(\\hat{x}, \\theta)) - \\varepsilon \\right) \\right]\n",
    "$$\n",
    "\n",
    "* So, in principle we can implement the approach with _a custom loss function_\n",
    "* In practice, things are trickier due to how the DIDI works:\n",
    "\n",
    "$$\n",
    "\\operatorname{DIDI}(y) = \\sum_{j \\in J_p} \\sum_{v \\in D_{j}} \\left|\\frac{1}{m} \\sum_{i=1}^m y_i - \\frac{1}{|I_{j,v}|} \\sum_{i \\in I_{j,v}} y_{i}\\right|\n",
    "$$\n",
    "\n",
    "* The computation requires information about the protected attribute\n",
    "* ...Which is not part of the ground truth (at least not by default)\n",
    "\n",
    "This makes things more complicated..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fairness as a Semantic Regularizer\n",
    "\n",
    "**...To the point that is easier to use a _custom Keras model_**\n",
    "\n",
    "```python\n",
    "class CstDIDIRegressor(keras.Model):\n",
    "    def __init__(self, base_pred, attributes, protected, alpha, thr): ...\n",
    "        \n",
    "    def call(self, data): ...\n",
    "\n",
    "    def train_step(self, data): ...\n",
    "\n",
    "    @property\n",
    "    def metrics(self): ...\n",
    "```\n",
    "\n",
    "* In the `__init__` method we pass all the additional information we need\n",
    "* The `call` method is called when evaluating the model\n",
    "* The `train_step` method is called by Keras while training\n",
    "\n",
    "The full code can be found in the support module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fairness as a Semantic Regularizer\n",
    "\n",
    "**Let's have a deeper look at a few methods**\n",
    "\n",
    "```python\n",
    "def __init__(self, base_pred, attributes, protected, alpha, thr):\n",
    "    super(CstDIDIModel, self).__init__()\n",
    "    self.base_pred = base_pred # Wrapped predictor\n",
    "    self.alpha = alpha # This is the penalizer weight (i.e. lambda)\n",
    "    self.thr = thr # This is the DIDI threshold (i.e. epsilon)\n",
    "    self.protected = {list(attributes).index(k): dom for k, dom in protected.items()}\n",
    "    ...\n",
    "\n",
    "def call(self, data):\n",
    "    return self.base_pred(data)\n",
    "```\n",
    "\n",
    "Our custom model is a _wrapper_ (in software engineering terms)\n",
    "\n",
    "* There's a second predictor stored as object field\n",
    "* ...Which we call whenever we need to perform estimates\n",
    "* Therefore, we can add our DIDI constraint _on top of any NN model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fairness as a Semantic Regularizer\n",
    "\n",
    "**The main logic is in the `train_step` method:**\n",
    "\n",
    "```python\n",
    "def train_step(self, data):\n",
    "    x, y_true = data # unpack the input\n",
    "    with tf.GradientTape() as tape: # loss computation\n",
    "        ...\n",
    "        loss = mse + self.alpha * cst\n",
    "\n",
    "    grads = tape.gradient(loss, self.trainable_variables) # gradient computation\n",
    "    self.optimizer.apply_gradients(zip(grads, tr_vars)) # update NN weights\n",
    "    ...\n",
    "```\n",
    "\n",
    "* We compute the loss inside a `GradientTape` object\n",
    "* This is used by TensorFlow to track tensor operations\n",
    "* ...So that they can be differentiated using the `gradient` method\n",
    "* We handle weight update using the usual optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fairness as a Semantic Regularizer\n",
    "\n",
    "**The main logic is in the `train_step` method:**\n",
    "\n",
    "```python\n",
    "def train_step(self, data):\n",
    "    ...\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = self.base_pred(x, training=True) # obtain predictions\n",
    "        mse = self.compiled_loss(y_true, y_pred) # compute base loss\n",
    "        ymean = tf.math.reduce_mean(y_pred) # here we start computing the DIDI\n",
    "        didi = 0\n",
    "        for aidx, dom in self.protected.items():\n",
    "            for val in dom:\n",
    "                mask = (x[:, aidx] == val)\n",
    "                didi += tf.math.abs(ymean - tf.math.reduce_mean(y_pred[mask]))\n",
    "        cst = tf.math.maximum(0.0, didi - self.thr)\n",
    "        loss = mse + self.alpha * cst\n",
    "    ...\n",
    "```\n",
    "\n",
    "We use tensor operations for the DIDI (so its gradient can be computed by TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Building the Constrained Model\n",
    "\n",
    "**We start by building (and wrapping) our predictor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected = {'race': (0, 1)}\n",
    "didi_thr = 1.0\n",
    "base_pred = util.build_nn_model(input_shape=len(attributes), output_shape=1, hidden=[])\n",
    "nn = util.CstDIDIModel(base_pred, attributes, protected, alpha=5, thr=didi_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without a clear clue for choosing the Lagrangian multipliers**\n",
    "\n",
    "...We picked $5$ as a guess\n",
    "\n",
    "* Choosing a good weight is obviously an important issue\n",
    "* We'll how to deal with that later\n",
    "\n",
    "**We will try to roughly halve the \"natural\" DIDI of the model**\n",
    "\n",
    "* Since for our baseline we have $\\operatorname{DIDI}(y) \\simeq 2$\n",
    "* ...Then we picked $\\varepsilon = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training the Constrained Model\n",
    "\n",
    "**We can train the constrained model as usual**\n",
    "\n",
    "* Since the constraint is for all the population, we have `batch_size=len(tr)`\n",
    "* We could use mini-batches, but that would result in some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred = util.build_nn_model(input_shape=len(attributes), output_shape=1, hidden=[])\n",
    "nn = util.CstDIDIModel(base_pred, attributes, protected, alpha=5, thr=didi_thr)\n",
    "history = util.train_nn_model(nn, tr[attributes], tr[target], loss='mse', validation_split=0., epochs=2000, batch_size=len(tr))\n",
    "util.plot_training_history(history, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Constrained Model Evaluation\n",
    "\n",
    "**Let's check both the prediction quality and the DIDI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pred = nn.predict(tr[attributes], verbose=0)\n",
    "r2_tr = r2_score(tr[target], tr_pred)\n",
    "ts_pred = nn.predict(ts[attributes], verbose=0)\n",
    "r2_ts = r2_score(ts[target], ts_pred)\n",
    "tr_DIDI = util.DIDI_r(tr, tr_pred, protected)\n",
    "ts_DIDI = util.DIDI_r(ts, ts_pred, protected)\n",
    "\n",
    "print(f'R2 score: {r2_tr:.2f} (training), {r2_ts:.2f} (test)')\n",
    "print(f'DIDI: {tr_DIDI:.2f} (training), {ts_DIDI:.2f} (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The constraint is satisfied (and the accuracy reduced, as expected)**\n",
    "\n",
    "...But _why is there some slack_ in terms of constraint satisfaction?\n",
    "\n",
    "* If $\\lambda$ were too small, we should have an infeasibility\n",
    "* Otherwise, we should have optimal accuracy. Is this what is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lagrangian Dual Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Choosing Multiplier Values\n",
    "\n",
    "**We are currently solving this problem**\n",
    "\n",
    "$$\n",
    "\\operatorname{argmin}_{\\theta} \\mathbb{E}\\left[ L(\\hat{y}, y) +\\lambda \\max\\left(0, g(y) \\right) \\right] \\quad\\text{ with: } y = f(\\hat{x}, \\theta)\n",
    "$$\n",
    "\n",
    "...By using (Stochastic) _Gradient Descent_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is an important detail**\n",
    "\n",
    "* A large $\\lambda$ may be fine theoretically\n",
    "* ...But it may cause the gradient to be _unstable_\n",
    "\n",
    "**Therefore:**\n",
    "\n",
    "* With a convex model, we should still reach convergence, but _slowly_\n",
    "* With a non-convex model, we may end up in a poor local optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=big>How can we deal with this?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Penalty Method\n",
    "\n",
    "**We can think of increasing $\\lambda$ gradually**\n",
    "\n",
    "...Which leads to the classical _penalty method_\n",
    "\n",
    "* $\\lambda^{(0)} = 1$\n",
    "* $\\theta^{(0)} = \\operatorname{argmin}_{\\theta} \\left\\{ L(y) + \\lambda^{(0)T} \\max(0, g(y)) \\right\\} \\text{ with: } y = f(\\hat{x}, \\theta)$\n",
    "* For $k = 1..n$\n",
    "  - If $g(y) \\leq 0$, stop\n",
    "  - Otherwise $\\lambda^{(k)} = r\\lambda^{(k)}$, with $r \\in (1, \\infty)$\n",
    "  - $\\theta^{(k)} = \\operatorname{argmin}_{\\theta} \\left\\{ L(y) + \\lambda^{(k)T} \\max(0, g(y)) \\right\\} \\text{ with: } y = f(\\hat{x}, \\theta)$\n",
    "\n",
    "**This can work, but there are a few issues**\n",
    "\n",
    "* $\\lambda$ grows quickly and may still become problematically large\n",
    "* Early and late stages in SGD may call for _different values of $\\lambda$_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Gradient Ascent to Control the Multipliers\n",
    "\n",
    "**A gentler approach consists in using _gradient ascent for the multipliers_**\n",
    "\n",
    "Let's consider our modified loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta, \\lambda) = L(\\hat{y}, f(\\hat{x}, \\theta)) +\\lambda^T \\max\\left(0, g(f(\\hat{x}, \\theta)) \\right)\n",
    "$$\n",
    "\n",
    "* This is actually differentiable in $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The gradient is also surprisingly simple:**\n",
    "\n",
    "$$\n",
    "\\nabla_{\\lambda} \\mathcal{L}(\\theta, \\lambda) = \\max\\left(0, g(f(\\hat{x}, \\theta))\\right)\n",
    "$$\n",
    "\n",
    "* For satisfied constraints, the partial derivative is 0\n",
    "* For violated constraints, it is equal to the violation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Dual Approach\n",
    "\n",
    "**Therefore, we can solve our constrained ML problem**\n",
    "\n",
    "...By alternating _gradient descent and ascent_:\n",
    "\n",
    "* $\\lambda^{(0)} = 0$\n",
    "* For $k = 1..n$ (or until convergence):\n",
    "  - Obtain $\\lambda^{(k)}$ via an ascent step with $\\nabla_{\\lambda} \\mathcal{L}(\\lambda, \\theta^{(k-1)})$\n",
    "  - Obtain $\\theta^{(k)}$ via a descent step with $\\nabla_{\\theta} \\mathcal{L}(\\lambda^{(k)}, \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technically, we are working with sub-gradients here**\n",
    "\n",
    "* When we make one optimization step\n",
    "* ...We always keep on set of variables fixed\n",
    "\n",
    "Still, this is often good enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Dual Approach\n",
    "\n",
    "**Therefore, we can solve our constrained ML problem**\n",
    "\n",
    "...By alternating _gradient descent and ascent_:\n",
    "\n",
    "* $\\lambda^{(0)} = 0$\n",
    "* $\\theta^{(0)} = \\operatorname{argmin}_\\theta \\mathcal{L}(\\lambda^{(0)}, \\theta)$\n",
    "* For $k = 1..n$ (or until convergence):\n",
    "  - Obtain $\\lambda^{(k)}$ via an ascent step with $\\nabla_{\\lambda} \\mathcal{L}(\\lambda, \\theta^{(k-1)})$\n",
    "  - Obtain $\\theta^{(k)}$ via a descent step with $\\nabla_{\\theta} \\mathcal{L}(\\lambda^{(k)}, \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**We might still reach impractical values for $\\lambda$**\n",
    "\n",
    "...But the gentle updates will keep the gradient more stable\n",
    "\n",
    "* At the beginning, SGD will be free to prioritize accuracy\n",
    "* After some iterations, both $\\theta$ and $\\lambda$ will be nearly (locally) optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementing the Lagrangian Dual Approach\n",
    "\n",
    "**We will implement the Lagrangian dual approach via another custom model**\n",
    "\n",
    "```python\n",
    "class LagDualDIDIRegressor(MLPRegressor):\n",
    "    def __init__(self, base_pred, attributes, protected, thr):\n",
    "        super(LagDualDIDIRegressor, self).__init__()\n",
    "        self.alpha = tf.Variable(0., name='alpha')\n",
    "        ...\n",
    "\n",
    "    def __custom_loss(self, x, y_true, sign=1): ...\n",
    "\n",
    "    def train_step(self, data): ...\n",
    "        \n",
    "    def metrics(self): ...\n",
    "```\n",
    "\n",
    "* We no longer pass a fixed `alpha` weight/multiplier\n",
    "* Instead we use a _trainable variable_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementing the Lagrangian Dual Approach\n",
    "\n",
    "**We move the loss function computation in a dedicated method (`__custom_loss`)**\n",
    "\n",
    "```python\n",
    "def __custom_loss(self, x, y_true, sign=1):\n",
    "    y_pred = self.base_pred(x, training=True) # obtain the predictions\n",
    "    mse = self.compiled_loss(y_true, y_pred) # main loss\n",
    "    ymean = tf.math.reduce_mean(y_pred) # average prediction\n",
    "    didi = 0 # DIDI computation\n",
    "    for aidx, dom in self.protected.items():\n",
    "        for val in dom:\n",
    "            mask = (x[:, aidx] == val)\n",
    "            didi += tf.math.abs(ymean - tf.math.reduce_mean(y_pred[mask]))\n",
    "    cst = tf.math.maximum(0.0, didi - self.thr) # regularizer\n",
    "    loss = mse + self.alpha * cst\n",
    "    return sign*loss, mse, cst\n",
    "```\n",
    "\n",
    "* The code is the same as before\n",
    "* ...Except that we can flip the loss sign via a function argument (i.e. `sign`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Implementing the Lagrangian Dual Approach\n",
    "\n",
    "**In the training method, we make _two distinct gradient steps:_**\n",
    "\n",
    "```python\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data # unpacking\n",
    "        with tf.GradientTape() as tape: # first loss (minimization)\n",
    "            loss, mse, cst = self.__custom_loss(x, y_true, sign=1)\n",
    "        tr_vars = self.trainable_variables\n",
    "        wgt_vars = tr_vars[:-1] # network weights\n",
    "        mul_vars = tr_vars[-1:] # multiplier\n",
    "        grads = tape.gradient(loss, wgt_vars) # adjust the network weights\n",
    "        self.optimizer.apply_gradients(zip(grads, wgt_vars))\n",
    "        with tf.GradientTape() as tape: # second loss (maximization)\n",
    "            loss, mse, cst = self.__custom_loss(x, y_true, sign=-1)\n",
    "        grads = tape.gradient(loss, mul_vars) # adjust lambda\n",
    "        self.optimizer.apply_gradients(zip(grads, mul_vars))\n",
    "```\n",
    "\n",
    "* In principle, we could even have used two distinct optimizers\n",
    "* That would allow to keep (e.g.) separate momentum vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Training the Lagrangian Dual Approach\n",
    "\n",
    "**The new approach leads _fewer oscillations at training time_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred = util.build_nn_model(input_shape=len(attributes), output_shape=1, hidden=[])\n",
    "nn2 = util.LagDualDIDIModel(base_pred, attributes, protected, thr=didi_thr)\n",
    "history = util.train_nn_model(nn2, tr[attributes], tr[target], loss='mse', validation_split=0., epochs=2000, batch_size=len(tr))\n",
    "util.plot_training_history(history, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lagrangian Dual Evaluation\n",
    "\n",
    "**Let's check the new results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pred2 = nn2.predict(tr[attributes], verbose=0)\n",
    "r2_tr2 = r2_score(tr[target], tr_pred2)\n",
    "ts_pred2 = nn2.predict(ts[attributes], verbose=0)\n",
    "r2_ts2 = r2_score(ts[target], ts_pred2)\n",
    "tr_DIDI2 = util.DIDI_r(tr, tr_pred2, protected)\n",
    "ts_DIDI2 = util.DIDI_r(ts, ts_pred2, protected)\n",
    "\n",
    "print(f'R2 score: {r2_tr2:.2f} (training), {r2_ts2:.2f} (test)')\n",
    "print(f'DIDI: {tr_DIDI2:.2f} (training), {ts_DIDI2:.2f} (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The DIDI has the desired value (on the test set, this is only roughly true)\n",
    "* ...And the prediction quality is _much higher than before_!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Comments\n",
    "\n",
    "**This is not the only approach for constrained ML**\n",
    "\n",
    "* There approaches based on projection, pre-processing, iterative projection...\n",
    "* ...And in some cases you can enforce constraints through the architecture itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...But it is simple and flexible**\n",
    "\n",
    "* You just need your constraint to be differentiable\n",
    "* ...And some good will to tweak the implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The approach can be used also for _symbolic knowledge injection_**\n",
    "\n",
    "* Perhaps domain experts can provide you some intuitive rule of thumbs\n",
    "* You model those as constraints and take them into account at training time\n",
    "* Just be careful with the weights, as in this case feasibility is not the goal"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "center": false,
   "enable_chalkboard": true,
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
